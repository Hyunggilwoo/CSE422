{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all the yaml data to a dict\n",
    "with open(\"newsgroup_data.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        newsgroup = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JaccardSimilarity(x, y):\n",
    "    # input: dict where key is word i and value is the occurance of the word in the document\n",
    "    num = 0\n",
    "    denom = 0\n",
    "    # find all the nuique keys of X Unione Y\n",
    "    UniqueWordsinXY = list(set(x.keys()) | set(y.keys()))\n",
    "    for word in UniqueWordsinXY:\n",
    "        xi = x.get(word, 0)\n",
    "        yi = y.get(word, 0)\n",
    "        num += min(xi, yi)\n",
    "        denom += max(xi, yi)\n",
    "    return num / denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def L2Similarity(x, y):\n",
    "    UniqueWordsinXY = list(set(x.keys()) | set(y.keys()))\n",
    "    sumSquare = 0\n",
    "    for word in UniqueWordsinXY:\n",
    "        xi = x.get(word, 0)\n",
    "        yi = y.get(word, 0)\n",
    "        sumSquare += (abs(xi - yi))**2\n",
    "    \n",
    "    return -np.sqrt(sumSquare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(x, y):\n",
    "    UniqueWordsinXY = list(set(x.keys()) | set(y.keys()))\n",
    "    num = 0\n",
    "    sumXSqr = 0\n",
    "    sumYSqr = 0\n",
    "    for word in UniqueWordsinXY:\n",
    "        xi = x.get(word, 0)\n",
    "        yi = y.get(word, 0)\n",
    "        num += xi * yi\n",
    "        sumXSqr += xi**2\n",
    "        sumYSqr += yi**2\n",
    "    return num / (np.sqrt(sumXSqr) * np.sqrt(sumYSqr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05886651103648987"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "# t1 = {1:2, 2:14, 5:2, 9:7} # 0.11111\n",
    "# t2 = {1:2, 4:4, 5:2, 10:7} # -17.606\n",
    "# JaccardSimilarity(t1,t2)\n",
    "# L2Similarity(t1,t2)\n",
    "# cosineSimilarity(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to calculate the average simlarity between two groups using the given metric\n",
    "\n",
    "def avg_similarity(groupA, groupB, metric):\n",
    "    # input: dict:\n",
    "    # {0: {3: 1,\n",
    "    #   10: 1,\n",
    "    #   12: 8,\n",
    "    #   17: 1}}\n",
    "    #   article: {word: # of occurances}\n",
    "    #   word 3 appears 1 times in article 0\n",
    "    # output the avg score between two groups\n",
    "    # each group has 50 articles\n",
    "    # method: function of your the metric method \n",
    "    all_scores = []\n",
    "    keys_A = list(groupA.keys())\n",
    "    keys_B = list(groupB.keys())\n",
    "    for i in range(50):\n",
    "        for j in range(50):\n",
    "            article_ai = groupA[keys_A[i]]\n",
    "            article_bj = groupB[keys_B[j]]\n",
    "            all_scores.append(metric(article_ai, article_bj))\n",
    "    return np.mean(all_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heapmap_matrix(avg_similarity, metric):\n",
    "    # input: a function of metric\n",
    "    # return a 20Ã—20 matrix with rows and columns indexed by newsgroups (in the same order)\n",
    "    matrix = np.zeros((20,20))\n",
    "    groups = list(newsgroup.keys())\n",
    "    for i in range(20):\n",
    "        group_i = newsgroup[groups[i]]\n",
    "        for j in range(20):\n",
    "            group_j = newsgroup[groups[j]]\n",
    "            matrix[i,j] = avg_similarity(group_i, group_j, metric)\n",
    "\n",
    "    return matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "def makeHeatMap(data, names, color, outputFileName):\n",
    "    fig, ax = plt.subplots()\n",
    "    #create the map w/ color bar legend\n",
    "    heatmap = ax.pcolor(data, cmap=color)\n",
    "    cbar = plt.colorbar(heatmap)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "\n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    ax.set_xticklabels(range(1, 21))\n",
    "    ax.set_yticklabels(names)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(outputFileName, format = 'png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = list(newsgroup.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeHeatMap(data = heapmap_matrix(avg_similarity, metric = JaccardSimilarity), names = groups, color = cm.Blues, outputFileName = \"Jaccard.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeHeatMap(data = heapmap_matrix(avg_similarity, metric = L2Similarity), names = groups, color = cm.Blues, outputFileName = \"L2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeHeatMap(data = heapmap_matrix(avg_similarity, metric = cosineSimilarity), names = groups, color = cm.Blues, outputFileName = \"Cosine.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Dimension reduction\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) [3 points] Baseline classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newsgroup dataset: 20 different groups and each groups contains 50 different articles  \n",
    "Total of 1000 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using Cosine Similarity for all 1000 articles\n",
    "\n",
    "# classify all 1000 articles\n",
    "# concat 1000 articles into one dict\n",
    "\n",
    "### pre-process the data\n",
    "y = np.repeat(range(20), 50) # labels of the articles\n",
    "documents = {} # 1000 articles\n",
    "\n",
    "for gp in groups:\n",
    "    documents.update(newsgroup[gp])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline_cosine_NN(doc):\n",
    "    # input: the number of the article\n",
    "    # for any given document, \n",
    "    # finds the document with largest cosine similarity \n",
    "    # and returns the corresponding newsgroup label\n",
    "    scores = {} # key: (article_i) : Cosine_score, The cosine score of article_i and doc\n",
    "    for art_i in documents:\n",
    "        # calculate the cosine for every possible articles\n",
    "        scores.update({art_i : cosineSimilarity(documents[art_i], doc)})\n",
    "\n",
    "    # find the art_j with the highest score\n",
    "    article_max = max(scores, key = scores.get)\n",
    "\n",
    "    # return the index of the classification label\n",
    "    return y[article_max]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_cosine_NN2(doc):\n",
    "    # input: the number of the article\n",
    "    # for any given document, \n",
    "    # finds the document with largest cosine similarity \n",
    "    # and returns the corresponding newsgroup label\n",
    "    scores = {} # key: (article_i) : Cosine_score, The cosine score of article_i and doc\n",
    "    filteredDoc = documents.copy()\n",
    "    filteredDoc.pop(doc)\n",
    "    for art_i in filteredDoc:\n",
    "        # calculate the cosine for every possible articles\n",
    "        scores.update({art_i : cosineSimilarity(filteredDoc[art_i], documents[doc])})\n",
    "\n",
    "    # find the art_j with the highest score\n",
    "    article_max = max(scores, key = scores.get)\n",
    "\n",
    "    # return the index of the classification label\n",
    "    return y[article_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21725017863742738"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cosineSimilarity(filtered_doc[1], newsgroup['talk.politics.misc'][900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(group, model = baseline_cosine_NN2):\n",
    "    # input: the news group\n",
    "    # return: list: a list of predicted labels of the article for the given group\n",
    "    labels = []\n",
    "    # for each article in this group\n",
    "    # we predict the label of group it belongs to\n",
    "    for art_num in group:\n",
    "        labels.append(model(doc = art_num))\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20Ã—20 matrix whose (A,B)\n",
    "#  entry is defined by the fraction of articles in group A\n",
    "#  that have their nearest neighbor in group B\n",
    "\n",
    "# (A,B) of the matrix implies the percentage of \n",
    "# labels in group A are classified as group B using Cosine \n",
    "def heapmap_classification():\n",
    "    # input: a function of metric\n",
    "    # return a 20Ã—20 matrix with rows and columns indexed by newsgroups (in the same order)\n",
    "    matrix = np.zeros((20,20))\n",
    "    groups = list(newsgroup.keys())\n",
    "    for i in range(20):\n",
    "        group_i = newsgroup[groups[i]]\n",
    "        pred_group_i = np.array(predict(group_i))\n",
    "        for j in range(20):        \n",
    "            # check how many predicted labels in group i is equal to j\n",
    "            matrix[i,j] = np.mean(pred_group_i == j)\n",
    "            \n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_error = heapmap_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeHeatMap(matrix_error, names = groups, color = cm.Blues, outputFileName = \"Cosine__Classification_NN.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
